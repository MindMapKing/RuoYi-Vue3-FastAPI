import json
# APScheduler äº‹ä»¶å¸¸é‡ï¼šç›‘å¬æ‰€æœ‰ç±»å‹çš„äº‹ä»¶ï¼ˆæ‰§è¡Œã€å¼‚å¸¸ã€æäº¤ç­‰ï¼‰
from apscheduler.events import EVENT_ALL
# å¼‚æ­¥ IO æ‰§è¡Œå™¨ï¼šç”¨äºè°ƒåº¦å¼‚æ­¥åç¨‹ä»»åŠ¡
from apscheduler.executors.asyncio import AsyncIOExecutor
# è¿›ç¨‹æ± æ‰§è¡Œå™¨ï¼šåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­è¿è¡Œä»»åŠ¡ï¼Œéš”ç¦»èµ„æº
from apscheduler.executors.pool import ProcessPoolExecutor
# å†…å­˜å‹ä»»åŠ¡å­˜å‚¨ï¼šä»»åŠ¡ä»…ä¿å­˜åœ¨å†…å­˜ï¼Œé‡å¯å³ä¸¢å¤±
from apscheduler.jobstores.memory import MemoryJobStore
# Redis ä»»åŠ¡å­˜å‚¨ï¼šå°†ä»»åŠ¡æŒä¹…åŒ–åˆ° Redisï¼Œæ”¯æŒåˆ†å¸ƒå¼
from apscheduler.jobstores.redis import RedisJobStore
# SQLAlchemy ä»»åŠ¡å­˜å‚¨ï¼šå°†ä»»åŠ¡æŒä¹…åŒ–åˆ°æ•°æ®åº“ï¼Œæ”¯æŒè·¨é‡å¯
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
# å¼‚æ­¥ IO è°ƒåº¦å™¨ï¼šåŸºäº asyncio çš„ä¸»è°ƒåº¦å¼•æ“
from apscheduler.schedulers.asyncio import AsyncIOScheduler
# ç»„åˆè§¦å‘å™¨ï¼šå¯å°†å¤šä¸ªè§¦å‘å™¨â€œæˆ–â€åœ¨ä¸€èµ·ï¼Œæ»¡è¶³å…¶ä¸€å³è§¦å‘
from apscheduler.triggers.combining import OrTrigger
# Cron è§¦å‘å™¨ï¼šæŒ‰ç±» Unix crontab è¡¨è¾¾å¼å‘¨æœŸæ€§è§¦å‘
from apscheduler.triggers.cron import CronTrigger
# ä¸€æ¬¡æ€§æ—¥æœŸè§¦å‘å™¨ï¼šåœ¨æŒ‡å®šæ—¶é—´ç‚¹è§¦å‘ä¸€æ¬¡
from apscheduler.triggers.date import DateTrigger
# å¼•å…¥ asyncio çš„ iscoroutinefunctionï¼Œç”¨äºåˆ¤æ–­ä¸€ä¸ªå‡½æ•°æ˜¯å¦ä¸ºå¼‚æ­¥åç¨‹å‡½æ•°
# åœ¨ add_scheduler_job ä¸ execute_scheduler_job_once ä¸­ï¼Œè‹¥ç›®æ ‡å‡½æ•°æ˜¯åç¨‹ï¼Œåˆ™å¼ºåˆ¶ä½¿ç”¨ AsyncIOExecutor('default') æ‰§è¡Œå™¨
from asyncio import iscoroutinefunction
from datetime import datetime, timedelta
from sqlalchemy.engine import create_engine
from sqlalchemy.orm import sessionmaker
from typing import Union
from config.database import AsyncSessionLocal, quote_plus
from config.env import DataBaseConfig, RedisConfig
from module_admin.dao.job_dao import JobDao
from module_admin.entity.vo.job_vo import JobLogModel, JobModel
from module_admin.service.job_log_service import JobLogService
from utils.log_util import logger
import module_task  # noqa: F401


# é‡å†™Cronå®šæ—¶
class MyCronTrigger(CronTrigger):
    @classmethod
    @classmethod
    def from_crontab(cls, expr: str, timezone=None):
        """
        ç±»æ–¹æ³•ï¼šå°† 6 æˆ– 7 ä½ crontab è¡¨è¾¾å¼è§£æä¸º MyCronTrigger å®ä¾‹ã€‚
        cls æ˜¯ç±»æœ¬èº«ï¼ˆMyCronTriggerï¼‰ï¼Œç”¨äºåœ¨ç±»æ–¹æ³•å†…éƒ¨åˆ›å»ºå¹¶è¿”å›å½“å‰ç±»çš„å®ä¾‹ã€‚
        """
        values = expr.split()
        if len(values) != 6 and len(values) != 7:
            raise ValueError('Wrong number of fields; got {}, expected 6 or 7'.format(len(values)))

        second = values[0]
        minute = values[1]
        hour = values[2]
        if '?' in values[3]:
            day = None
        elif 'L' in values[5]:
            day = f"last {values[5].replace('L', '')}"
        elif 'W' in values[3]:
            day = cls.__find_recent_workday(int(values[3].split('W')[0]))
        else:
            day = values[3].replace('L', 'last')
        month = values[4]
        if '?' in values[5] or 'L' in values[5]:
            week = None
        elif '#' in values[5]:
            week = int(values[5].split('#')[1])
        else:
            week = values[5]
        if '#' in values[5]:
            day_of_week = int(values[5].split('#')[0]) - 1
        else:
            day_of_week = None
        year = values[6] if len(values) == 7 else None
        return cls(
            second=second,
            minute=minute,
            hour=hour,
            day=day,
            month=month,
            week=week,
            day_of_week=day_of_week,
            year=year,
            timezone=timezone,
        )

    @classmethod
    def __find_recent_workday(cls, day: int):
        now = datetime.now()
        date = datetime(now.year, now.month, day)
        if date.weekday() < 5:
            return date.day
        else:
            diff = 1
            while True:
                previous_day = date - timedelta(days=diff)
                if previous_day.weekday() < 5:
                    return previous_day.day
                else:
                    diff += 1


SQLALCHEMY_DATABASE_URL = (
    f'mysql+pymysql://{DataBaseConfig.db_username}:{quote_plus(DataBaseConfig.db_password)}@'
    f'{DataBaseConfig.db_host}:{DataBaseConfig.db_port}/{DataBaseConfig.db_database}'
)
if DataBaseConfig.db_type == 'postgresql':
    SQLALCHEMY_DATABASE_URL = (
        f'postgresql+psycopg2://{DataBaseConfig.db_username}:{quote_plus(DataBaseConfig.db_password)}@'
        f'{DataBaseConfig.db_host}:{DataBaseConfig.db_port}/{DataBaseConfig.db_database}'
    )
engine = create_engine(
    SQLALCHEMY_DATABASE_URL,
    echo=DataBaseConfig.db_echo,
    max_overflow=DataBaseConfig.db_max_overflow,
    pool_size=DataBaseConfig.db_pool_size,
    pool_recycle=DataBaseConfig.db_pool_recycle,
    pool_timeout=DataBaseConfig.db_pool_timeout,
)
# SessionLocal æ˜¯ä¸€ä¸ª SQLAlchemy çš„åŒæ­¥ä¼šè¯å·¥å‚ï¼Œç”¨äºåœ¨åŒæ­¥ä»£ç ï¼ˆå¦‚ scheduler_event_listenerï¼‰ä¸­
# è·å–æ•°æ®åº“ä¼šè¯ï¼Œä»¥ä¾¿å°†ä»»åŠ¡æ—¥å¿—å†™å…¥æ•°æ®åº“ã€‚
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
job_stores = {
    'default': MemoryJobStore(),
    'sqlalchemy': SQLAlchemyJobStore(url=SQLALCHEMY_DATABASE_URL, engine=engine),
    'redis': RedisJobStore(
        **dict(
            host=RedisConfig.redis_host,
            port=RedisConfig.redis_port,
            username=RedisConfig.redis_username,
            password=RedisConfig.redis_password,
            db=RedisConfig.redis_database,
        )
    ),
}
executors = {'default': AsyncIOExecutor(), 'processpool': ProcessPoolExecutor(5)}
job_defaults = {'coalesce': False, 'max_instance': 1}
scheduler = AsyncIOScheduler()
scheduler.configure(jobstores=job_stores, executors=executors, job_defaults=job_defaults)


class SchedulerUtil:
    """
    å®šæ—¶ä»»åŠ¡ç›¸å…³æ–¹æ³•
    """

    @classmethod
    async def init_system_scheduler(cls):
        """
        åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–å®šæ—¶ä»»åŠ¡

        :return:
        """
        logger.info('ğŸ” å¼€å§‹å¯åŠ¨å®šæ—¶ä»»åŠ¡...')
        scheduler.start()
        async with AsyncSessionLocal() as session:
            job_list = await JobDao.get_job_list_for_scheduler(session)
            for item in job_list:
                cls.remove_scheduler_job(job_id=str(item.job_id))
                cls.add_scheduler_job(item)
        scheduler.add_listener(cls.scheduler_event_listener, EVENT_ALL)
        logger.info('âœ…ï¸ ç³»ç»Ÿåˆå§‹å®šæ—¶ä»»åŠ¡åŠ è½½æˆåŠŸ')

    @classmethod
    async def close_system_scheduler(cls):
        """
        åº”ç”¨å…³é—­æ—¶å…³é—­å®šæ—¶ä»»åŠ¡

        :return:
        """
        scheduler.shutdown()
        logger.info('âœ…ï¸ å…³é—­å®šæ—¶ä»»åŠ¡æˆåŠŸ')

    @classmethod
    def get_scheduler_job(cls, job_id: Union[str, int]):
        """
        æ ¹æ®ä»»åŠ¡idè·å–ä»»åŠ¡å¯¹è±¡

        :param job_id: ä»»åŠ¡id
        :return: ä»»åŠ¡å¯¹è±¡
        """
        query_job = scheduler.get_job(job_id=str(job_id))

        return query_job

    @classmethod
    def add_scheduler_job(cls, job_info: JobModel):
        """
        æ ¹æ®è¾“å…¥çš„ä»»åŠ¡å¯¹è±¡ä¿¡æ¯æ·»åŠ ä»»åŠ¡

        :param job_info: ä»»åŠ¡å¯¹è±¡ä¿¡æ¯
        :return:
        """
        job_func = eval(job_info.invoke_target)
        job_executor = job_info.job_executor
        if iscoroutinefunction(job_func):
            job_executor = 'default'
        scheduler.add_job(
            func=eval(job_info.invoke_target),
            trigger=MyCronTrigger.from_crontab(job_info.cron_expression),
            args=job_info.job_args.split(',') if job_info.job_args else None,
            kwargs=json.loads(job_info.job_kwargs) if job_info.job_kwargs else None,
            id=str(job_info.job_id),
            name=job_info.job_name,
            misfire_grace_time=1000000000000 if job_info.misfire_policy == '3' else None,
            coalesce=True if job_info.misfire_policy == '2' else False,
            max_instances=3 if job_info.concurrent == '0' else 1,
            jobstore=job_info.job_group,
            executor=job_executor,
        )

    @classmethod
    def execute_scheduler_job_once(cls, job_info: JobModel):
        """
        æ ¹æ®è¾“å…¥çš„ä»»åŠ¡å¯¹è±¡æ‰§è¡Œä¸€æ¬¡ä»»åŠ¡

        :param job_info: ä»»åŠ¡å¯¹è±¡ä¿¡æ¯
        :return:
        """
        job_func = eval(job_info.invoke_target)
        job_executor = job_info.job_executor
        if iscoroutinefunction(job_func):
            job_executor = 'default'
        job_trigger = DateTrigger()
        if job_info.status == '0':
            job_trigger = OrTrigger(triggers=[DateTrigger(), MyCronTrigger.from_crontab(job_info.cron_expression)])
        scheduler.add_job(
            func=eval(job_info.invoke_target),
            trigger=job_trigger,
            args=job_info.job_args.split(',') if job_info.job_args else None,
            kwargs=json.loads(job_info.job_kwargs) if job_info.job_kwargs else None,
            id=str(job_info.job_id),
            name=job_info.job_name,
            misfire_grace_time=1000000000000 if job_info.misfire_policy == '3' else None,
            coalesce=True if job_info.misfire_policy == '2' else False,
            max_instances=3 if job_info.concurrent == '0' else 1,
            jobstore=job_info.job_group,
            executor=job_executor,
        )

    @classmethod
    def remove_scheduler_job(cls, job_id: Union[str, int]):
        """
        æ ¹æ®ä»»åŠ¡idç§»é™¤ä»»åŠ¡

        :param job_id: ä»»åŠ¡id
        :return:
        """
        query_job = cls.get_scheduler_job(job_id=job_id)
        if query_job:
            scheduler.remove_job(job_id=str(job_id))

    @classmethod
    def scheduler_event_listener(cls, event):
        """
        APScheduler äº‹ä»¶ç›‘å¬å™¨ï¼šå½“è°ƒåº¦å™¨äº§ç”Ÿä»»ä½•äº‹ä»¶ï¼ˆä»»åŠ¡æäº¤ã€æ‰§è¡ŒæˆåŠŸã€æ‰§è¡Œå¼‚å¸¸ç­‰ï¼‰æ—¶è¢«å›è°ƒï¼Œ
        è´Ÿè´£æŠŠäº‹ä»¶çš„æ ¸å¿ƒä¿¡æ¯è½åº“åˆ° sys_job_log è¡¨ï¼Œæ–¹ä¾¿åå°æŸ¥çœ‹ä»»åŠ¡æ‰§è¡Œå†å²ä¸å¼‚å¸¸åŸå› ã€‚
        """
        # è·å–äº‹ä»¶ç±»å‹å’Œä»»åŠ¡ID
        event_type = event.__class__.__name__
        # è·å–ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸ä¿¡æ¯
        status = '0'
        exception_info = ''
        if event_type == 'JobExecutionEvent' and event.exception:
            exception_info = str(event.exception)
            status = '1'
        if hasattr(event, 'job_id'):
            job_id = event.job_id
            query_job = cls.get_scheduler_job(job_id=job_id)
            if query_job:
                query_job_info = query_job.__getstate__()
                # è·å–ä»»åŠ¡åç§°
                job_name = query_job_info.get('name')
                # è·å–ä»»åŠ¡ç»„å
                job_group = query_job._jobstore_alias
                # è·å–ä»»åŠ¡æ‰§è¡Œå™¨
                job_executor = query_job_info.get('executor')
                # è·å–è°ƒç”¨ç›®æ ‡å­—ç¬¦ä¸²
                invoke_target = query_job_info.get('func')
                # è·å–è°ƒç”¨å‡½æ•°ä½ç½®å‚æ•°
                job_args = ','.join(query_job_info.get('args'))
                # è·å–è°ƒç”¨å‡½æ•°å…³é”®å­—å‚æ•°
                job_kwargs = json.dumps(query_job_info.get('kwargs'))
                # è·å–ä»»åŠ¡è§¦å‘å™¨
                job_trigger = str(query_job_info.get('trigger'))
                # æ„é€ æ—¥å¿—æ¶ˆæ¯
                job_message = f"äº‹ä»¶ç±»å‹: {event_type}, ä»»åŠ¡ID: {job_id}, ä»»åŠ¡åç§°: {job_name}, æ‰§è¡Œäº{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                job_log = JobLogModel(
                    jobName=job_name,
                    jobGroup=job_group,
                    jobExecutor=job_executor,
                    invokeTarget=invoke_target,
                    jobArgs=job_args,
                    jobKwargs=job_kwargs,
                    jobTrigger=job_trigger,
                    jobMessage=job_message,
                    status=status,
                    exceptionInfo=exception_info,
                    createTime=datetime.now(),
                )
                session = SessionLocal()
                JobLogService.add_job_log_services(session, job_log)
                session.close()
